%!TEX root = ../main.tex
\documentclass[../main.tex]{subfiles}
\begin{document}

This chapter details the design and implementation of the MPDT$\rightarrow$MPDT-UD conversion pipeline. The conversion is a complex, multi-stage process, divided into two primary phases: 1. morphosyntactic mapping (Section~\ref{sec:morpho_conversion}) and 2. dependency tree transformation (Section~\ref{sec:dep_conversion}). Before detailing them, the chapter first describes the overall architecture of the converter, including its custom data structures and the code repository layout (Section~\ref{sec:converter_architecture}), the high-level processing workflow (Section~\ref{sec:pipeline}), and at the end--the auditable logging system that fulfills research goal \textbf{(R2)} (Section~\ref{sec:logging}).

\section{Converter Architecture and Environment}
\label{sec:converter_architecture}

The entire conversion process is implemented in~Python, leveraging a~custom-built environment designed for traceability and modularity. The code is publicly available in a~GitHub repository: \url{https://github.com/kvmilos/MPDT-to-UD-converter}.

\subsection{Core Data Structures}

The environment is built around core data structures, \texttt{Sentence} and \texttt{Token} classes, defined in~\texttt{utils/classes.py}. A~key design choice is that each \texttt{Token} object stores both the original MPDT annotation and the new, converted UD annotation in~parallel. This allows conversion rules to~access the original, unmodified MPDT context at~any stage, which is crucial for resolving ambiguity during the complex dependency transformation phase.

The \texttt{Token} class is also equipped with~numerous helper properties and methods to~simplify the writing of~conversion rules, such as methods accessing the governor in~the new UD tree if it is present, and accessing the old one otherwise, or traversing the tree to find specific dependents or governors via~certain relations.

\subsection{Project Repository Structure}
\label{sec:repo_structure}

The converter's code is organized into modules based on functionality. The main modules handle the top-level pipeline, morphosyntactic conversion, dependency conversion, and utilities. The structure of the repository is as follows (directories are shown in~blue):
\\

\dirtree{%
.1 \color{blue}{ud\_converter/}.
.2 converter.py.
.2 \color{blue}{morphosyntax/}.
.3 \color{blue}{pos\_categories/}.
.3 preconversion.py.
.3 conversion.py.
.3 postconversion.py.
.3 morphosyntax.py.
.2 \color{blue}{dependency/}.
.3 \color{blue}{structures/}.
.3 labels.py.
.3 edges.py.
.3 preconversion.py.
.3 conversion.py.
.3 postconversion.py.
.2 \color{blue}{utils/}.
.3 classes.py.
.3 constants.py.
.3 io.py.
.3 logger.py.
.2 \color{blue}{data/}.
.2 \color{blue}{logs/}.
}

\color{white}{.}\\
\color{black}
The main components are:

\begin{itemize}[leftmargin=2em]
    \item \texttt{converter.py}: The main executable script that orchestrates the entire conversion pipeline.
    \item \texttt{morphosyntax}: The package for Phase 1 (morphosyntactic conversion).
    \begin{itemize}[leftmargin=2em]
        \item \texttt{pos\_categories}: Contains a separate module for most MPDT \texttt{XPOS} tags (e.g., \texttt{subst.py}, \texttt{adj.py}) to handle its specific conversion rules.
    \end{itemize}
    \item \texttt{dependency}: The package for Phase 2 (dependency conversion).
    \begin{itemize}[leftmargin=2em]
        \item \texttt{structures}: Contains modules for restructuring specific syntactic constructions (e.g., \texttt{coordination.py}, \texttt{prepositional.py}).
    \end{itemize}
    \item \texttt{utils}: Utility package with helper modules for the entire application.
    \begin{itemize}[leftmargin=2em]
        \item \texttt{classes.py}: Defines the core \texttt{Sentence} and \texttt{Token} objects.
        \item \texttt{constants.py}: A central store for all static mappings (e.g., features, lemmas).
        \item \texttt{io.py}: Handles reading input \texttt{.conll} and \texttt{.json} files and writing the output \texttt{.conllu} file.
        \item \texttt{logger.py}: Implements the auditable logging system, including the \texttt{ChangeCollector} and \texttt{LoggingDict} classes.
    \end{itemize}
    \item \texttt{data/}: Default directory for input and output data files.
    \item \texttt{logs/}: Default directory where the detailed conversion logs are saved.
\end{itemize}

\section{Conversion Pipeline}
\label{sec:pipeline}

The converter is designed as a sequential pipeline, executed from the main \texttt{converter.py} script. From the user's perspective, the process consists of four main stages:

\begin{enumerate}[label=(\arabic*), leftmargin=2em]
    \item \textbf{Data Loading:} The pipeline begins by reading two input files: the MPDT treebank in its \texttt{.conll} format and a corresponding \texttt{.json} metadata file. The data is loaded into the custom \texttt{Sentence} and \texttt{Token} objects.

    \item \textbf{Phase 1: Morphosyntactic Conversion:} The first processing stage performs a rule-based conversion of the MPDT morphosyntactic annotations into their UD counterparts.

    \item \textbf{Phase 2: Dependency Conversion:} The second processing stage transforms the syntactic structure of the trees. This highly contextual phase converts the MPDT dependency relations to UD relations and restructures the tree topology to conform to UD guidelines.

    \item \textbf{Output Generation:} Finally, the converted \texttt{Sentence} and \texttt{Token} objects, now populated with UD annotations, are written to a single output \texttt{.conllu} file.
\end{enumerate}

The converter can be run in two modes. By default, it executes the complete pipeline. However, if the user provides the \texttt{--tags-only} command-line flag, the pipeline omits Phase 2. This allows a user to generate a file with only the morphosyntactic conversion applied, leaving the original MPDT dependency structure intact.

\section{Phase 1: Morphosyntactic Conversion}

The first phase, handled by~the \texttt{morphosyntax/} module, converts MPDT \texttt{XPOS} tags and features to their \texttt{UPOS} and \texttt{FEATS} counterparts. As shown in~\texttt{morphosyntax/morphosyntax.py}, this phase itself is a~three-step pipeline.

\subsection{Pre-conversion}
First, \texttt{morphosyntax/preconversion.py} applies a~set of~lemma-based rules. These rules override the POS-specific logic for~specific lexical items. For example:
\begin{itemize}[leftmargin=2em]
    \item Conjunctions like \textit{ni≈º}, \textit{jakby}, and \textit{niczym} are unambiguously mapped to \texttt{SCONJ} with \texttt{ConjType=Comp}.
    \item The lemma \textit{temu} is mapped to \texttt{ADP} with \texttt{AdpType=Post}.
    \item Words with~initial capitalization (and not otherwise classified) are provisionally tagged \texttt{PROPN}, correcting for~cases where a~proper noun was tagged as~a~common noun (\texttt{subst}).
\end{itemize}

\subsection{Core POS Conversion}
Next, the main \texttt{morphosyntax/conversion.py} script acts as~a~dispatcher, routing each token to~a~dedicated function based on~its MPDT \texttt{pos} tag. These functions, located in~the \texttt{morphosyntax/pos\_categories/} directory, implement the one-to-one and one-to-many mappings.

For example, the function \texttt{morphosyntax/pos\_categories/noun.py:subst} handles \texttt{subst} (noun) tokens. While most are mapped to \texttt{NOUN}, it checks for~pronominal lemmas (e.g., \textit{kto}, \textit{co}, \textit{nikt}) and maps them to \texttt{PRON} with the corresponding \texttt{PronType}.

This module also handles the specific Middle Polish phenomena described in~\autoref{chap:language}.
\begin{itemize}[leftmargin=2em]
    \item \texttt{adjb} (short adjective) is mapped to \texttt{UPOS=ADJ} + \texttt{Variant=Short}.
    \item \texttt{ppasb} (short passive participle) is mapped to \texttt{UPOS=ADJ} + \texttt{VerbForm=Part}, \texttt{Voice=Pass}, \texttt{Variant=Short}.
    \item The \texttt{helpers.py} module correctly maps the PDB gender system (e.g., \texttt{manim1}) to~the UD features \texttt{Gender=Masc} and \texttt{Animacy=Hum}, and preserves the \texttt{Number=Dual} feature.
\end{itemize}

\subsection{Post-conversion}
Finally, \texttt{morphosyntax/postconversion.py} performs sentence-level cleanup. Its two main tasks are:
\begin{enumerate}[leftmargin=2em]
    \item \textbf{Reconstructing Multiword Tokens:} Using the original sentence \texttt{"text"} from~the metadata, the \texttt{add\_mwe} function identifies tokens that are not separated by~a~space. This is essential for handling Middle Polish clitics, correctly grouping forms like \textit{kiedym} into an MWE that spans the syntactic words \textit{kiedy}  and \textit{m}.
    \item \textbf{Annotating Spaces:} The \texttt{add\_no\_space\_misc} function analyzes the same text to add \texttt{SpaceAfter=No} to~the \texttt{MISC} column for~tokens that are immediately followed by~another token or punctuation, a~requirement for~the CoNLL-U format.
\end{enumerate}

\section{Phase 2: Dependency Conversion}

The second phase, managed by~the \texttt{dependency/} module, is significantly more complex. Unlike morphosyntax, dependency conversion is not token-local; rules must consider a~token's governor, its dependents, and its siblings, often operating on~the original PDB structure, the partially converted UD structure, or both.

Many of~the structural transformations were adapted from~the principles established for~the conversion of~the contemporary Polish Dependency Bank (PDB$\rightarrow$PDB-UD) \parencite{wroblewska-2018-extended, wroblewska-2020-towards}, but were re-implemented to~fit the custom pipeline and~handle Middle Polish phenomena. The conversion follows a~strict pipeline, defined in~\texttt{dependency/conversion.py}.

\subsection{Structural Restructuring}
The first and most critical step is to~change the topology of~the dependency tree. The \texttt{dependency/structures/} directory contains modules for~specific syntactic constructions. The two most fundamental transformations, which were illustrated in~\autoref{fig:pdb-example} and \autoref{fig:ud-example}, are:

\begin{itemize}[leftmargin=2em]
    \item \textbf{Prepositional Phrases:} In~PDB, a~preposition (\texttt{prep}) governs its nominal complement (\texttt{comp}). The \texttt{dependency/structures/prepositional.py} module inverts this: the nominal complement becomes the head, it inherits the dependency relation from~the preposition (e.g., \texttt{adjunct} $\rightarrow$ \texttt{obl}), and the preposition is re-attached to~the noun with the \texttt{case} relation.
    
    \item \textbf{Coordination:} In~PDB, the coordinating conjunction (\texttt{conj}) is the head of~the coordinated elements (\texttt{conjunct}). The \texttt{dependency/structures/coordination.py} module restructures this by~promoting the \emph{first} conjunct to~be the head. Subsequent conjuncts are attached to~the first with the \texttt{conj} relation, and the conjunction itself is attached to~its \emph{following} conjunct with the \texttt{cc} relation.
\end{itemize}

Similar restructuring logic is applied to~copula constructions (\texttt{copula.py}), numeral phrases (\texttt{numeral.py}), and subordinate clauses (\texttt{subordination.py}).

\subsection{Label Mapping}
After the tree structure is finalized, the \texttt{dependency/labels.py} module traverses the tree and assigns a~final \texttt{udep\_label} to~each token. This mapping is highly context-sensitive. For~example, the generic PDB \texttt{adjunct} relation is mapped to~a~variety of~UD relations based on~the UPOS of~the head and the dependent:
\begin{itemize}[leftmargin=2em]
    \item \texttt{adjunct} on~a~\texttt{NOUN} dependent $\rightarrow$ \texttt{nmod}
    \item \texttt{adjunct} on~an \texttt{ADJ} dependent $\rightarrow$ \texttt{amod}
    \item \texttt{adjunct} on~an \texttt{ADV} dependent $\rightarrow$ \texttt{advmod}
    \item \texttt{adjunct} (prepositional phrase) on~a~\texttt{VERB} $\rightarrow$ \texttt{obl}
    \item \texttt{adjunct} (clausal) on~a~\texttt{VERB} $\rightarrow$ \texttt{advcl}
\end{itemize}

\subsection{Correction and Post-processing}
Finally, a~series of~cleanup scripts are run. \texttt{dependency/edges.py} ensures UD validation compliance by~removing disallowed dependents (e.g., a~\texttt{case} token cannot have its own dependents).

The \texttt{dependency/postconversion.py} module handles final tasks, such as disambiguating pronouns (\texttt{PronType=Int,Rel} $\rightarrow$ \texttt{PronType=Int} or \texttt{PronType=Rel} based on~tree context) and, most importantly, generating the enhanced dependency graph (\texttt{DEPS} column) by~propagating shared dependents in~coordination, fulfilling goal \textbf{(R3)}.

\section{Processing Workflow}

From a~user's perspective, the pipeline is executed via~a~single command. The converter takes the MPDT \texttt{.conll} file and the corresponding metadata \texttt{.json} file as~input.

\begin{verbatim}
python converter.py input_file.conll output_file.conllu meta_file.json
\end{verbatim}

The script processes each sentence and saves the result in~the specified \texttt{output\_file.conllu} in~the valid CoNLL-U format, ready for~validation and downstream use.

\end{document}