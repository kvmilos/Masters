%!TEX root = ../main.tex
\documentclass[../main.tex]{subfiles}
\begin{document}

This chapter details the design and implementation of the MPDT$\rightarrow$MPDT-UD conversion pipeline. The conversion is a complex, multi-stage process, divided into two primary phases: 1. morphosyntactic mapping (Section~\ref{sec:morpho_conversion}) and 2. dependency tree transformation (Section~\ref{sec:dep_conversion}). Before detailing them, the chapter first describes the overall architecture of the converter, including its custom data structures and the code repository layout (Section~\ref{sec:converter_architecture}), the high-level processing workflow (Section~\ref{sec:pipeline}), and at the end--the auditable logging system that fulfills research goal \textbf{(R2)} (Section~\ref{sec:logging}).

\section{Converter Architecture and Environment}
\label{sec:converter_architecture}

The entire conversion process is implemented in~Python, leveraging a~custom-built environment designed for traceability and modularity. The code is publicly available in a~GitHub repository: \url{https://github.com/kvmilos/MPDT-to-UD-converter}.

\subsection{Core Data Structures}

The environment is built around core data structures, \texttt{Sentence} and \texttt{Token} classes, defined in~\texttt{utils/classes.py}. A~key design choice is that each \texttt{Token} object stores both the original MPDT annotation and the new, converted UD annotation in~parallel. This allows conversion rules to~access the original, unmodified MPDT context at~any stage, which is crucial for resolving ambiguity during the complex dependency transformation phase.

The \texttt{Token} class is also equipped with~numerous helper properties and methods to~simplify the writing of~conversion rules, such as methods accessing the governor in~the new UD tree if it is present, and accessing the old one otherwise, or traversing the tree to find specific dependents or governors via~certain relations.

\subsection{Project Repository Structure}
\label{sec:repo_structure}

The converter's code is organized into modules based on functionality. The main modules handle the top-level pipeline, morphosyntactic conversion, dependency conversion, and utilities. The structure of the repository is as follows (directories are shown in~blue):
\\

\dirtree{%
.1 \color{blue}{ud\_converter/}.
.2 converter.py.
.2 \color{blue}{morphosyntax/}.
.3 \color{blue}{pos\_categories/}.
.3 preconversion.py.
.3 conversion.py.
.3 postconversion.py.
.3 morphosyntax.py.
.2 \color{blue}{dependency/}.
.3 \color{blue}{structures/}.
.3 labels.py.
.3 edges.py.
.3 preconversion.py.
.3 conversion.py.
.3 postconversion.py.
.2 \color{blue}{utils/}.
.3 classes.py.
.3 constants.py.
.3 io.py.
.3 logger.py.
.2 \color{blue}{data/}.
.2 \color{blue}{logs/}.
}

\color{white}{.}\\
\color{black}
The main components are:

\begin{itemize}[leftmargin=2em]
    \item \texttt{converter.py}: The main executable script that orchestrates the entire conversion pipeline.
    \item \texttt{morphosyntax}: The package for Phase 1 (morphosyntactic conversion).
    \begin{itemize}[leftmargin=2em]
        \item \texttt{pos\_categories}: Contains a separate module for most MPDT \texttt{XPOS} tags (e.g., \texttt{subst.py}, \texttt{adj.py}) to handle its specific conversion rules.
    \end{itemize}
    \item \texttt{dependency}: The package for Phase 2 (dependency conversion).
    \begin{itemize}[leftmargin=2em]
        \item \texttt{structures}: Contains modules for restructuring specific syntactic constructions (e.g., \texttt{coordination.py}, \texttt{prepositional.py}).
    \end{itemize}
    \item \texttt{utils}: Utility package with helper modules for the entire application.
    \begin{itemize}[leftmargin=2em]
        \item \texttt{classes.py}: Defines the core \texttt{Sentence} and \texttt{Token} objects.
        \item \texttt{constants.py}: A central store for all static mappings (e.g., features, lemmas).
        \item \texttt{io.py}: Handles reading input \texttt{.conll} and \texttt{.json} files and writing the output \texttt{.conllu} file.
        \item \texttt{logger.py}: Implements the auditable logging system, including the \texttt{ChangeCollector} and \texttt{LoggingDict} classes.
    \end{itemize}
    \item \texttt{data/}: Default directory for input and output data files.
    \item \texttt{logs/}: Default directory where the detailed conversion logs are saved.
\end{itemize}

\section{Conversion Pipeline}
\label{sec:pipeline}

The converter is designed as a sequential pipeline, executed from the main \texttt{converter.py} script. From the user's perspective, the process consists of four main stages:

\begin{enumerate}[label=(\arabic*), leftmargin=2em]
    \item \textbf{Data Loading:} The pipeline begins by reading two input files: the MPDT treebank in its \texttt{.conll} format and a corresponding \texttt{.json} metadata file. The data is loaded into the custom \texttt{Sentence} and \texttt{Token} objects.

    \item \textbf{Phase 1: Morphosyntactic Conversion:} The first processing stage performs a rule-based conversion of the MPDT morphosyntactic annotations into their UD counterparts.

    \item \textbf{Phase 2: Dependency Conversion:} The second processing stage transforms the syntactic structure of the trees. This highly contextual phase converts the MPDT dependency relations to UD relations and restructures the tree topology to conform to UD guidelines.

    \item \textbf{Output Generation:} Finally, the converted \texttt{Sentence} and \texttt{Token} objects, now populated with UD annotations, are written to a single output \texttt{.conllu} file.
\end{enumerate}

The converter can be run in two modes. By default, it executes the complete pipeline. However, if the user provides the \texttt{--tags-only} command-line flag, the pipeline omits Phase 2. This allows a user to generate a file with only the morphosyntactic conversion applied, leaving the original MPDT dependency structure intact.

\section{Phase 1: Morphosyntactic Conversion}

The first processing phase, handled by the \texttt{morphosyntax} module, converts the MPDT \texttt{XPOS} tags and morphological features into their \texttt{UPOS} and \texttt{FEATS} counterparts. This phase is executed as a three-step sub-pipeline for each sentence.

\subsection{Pre-conversion}
First, a set of lemma-based rules are applied to handle specific lexical items whose categorization overrides the more general \texttt{XPOS}-based rules. For example:
\begin{itemize}[leftmargin=2em]
    \item Conjunctions like \textit{ni≈º}, \textit{jakby}, and \textit{niczym}, which introduce comparisons, are unambiguously mapped to \texttt{SCONJ} (subordinating conjunction) and assigned the feature \texttt{ConjType=Comp} to mark this comparative function.
    \item The lemma \textit{temu}, when used as a postposition (e.g., \textit{dwa lata temu} `two years ago'), is mapped to \texttt{ADP} (adposition) and assigned the feature \texttt{AdpType=Post} to explicitly mark it as a postposition, distinguishing it from the standard prepositional form.
    \item Words with an initial capital letter that are not otherwise classified (e.g., as verbs) are provisionally tagged \texttt{PROPN} (proper noun). This rule helps correct cases where a proper noun was ambiguously tagged as a common noun (\texttt{subst}).
\end{itemize}

\subsection{Core POS Conversion}
Next, the main conversion logic maps the MPDT \texttt{XPOS} tag of each token to its corresponding \texttt{UPOS} tag and \texttt{FEATS}. The converter dispatches each token to a dedicated function based on its \texttt{XPOS} tag.

This design handles both simple and complex conversions. For instance, while \texttt{conj} (coordinating conjunction) almost always becomes \texttt{CCONJ}, the \texttt{subst} (noun) tag requires more logic: most \texttt{subst} tokens are mapped to \texttt{NOUN}, but the converter first checks for pronominal lemmas (e.g., \textit{kto}, \textit{co}, \textit{nikt}) and maps these to \texttt{PRON} (pronoun) with the appropriate \texttt{PronType} feature.

This module also handles the specific Middle Polish phenomena described in Chapter~\ref{chap:language}:
\begin{itemize}[leftmargin=2em]
    \item \texttt{adjb} (short adjective) is mapped to \texttt{UPOS=ADJ} and given the feature \texttt{Variant=Short}.
    \item \texttt{ppasb} (short passive participle) is mapped to \texttt{UPOS=ADJ} with the features \texttt{VerbForm=Part}, \texttt{Voice=Pass}, and \texttt{Variant=Short}.
    \item The MPDT gender system is correctly mapped to the UD features (e.g., \texttt{manim1} to \texttt{Gender=Masc} and \texttt{Animacy=Hum}).
    \item The Middle Polish \texttt{Number=Dual} feature is preserved, as it is a valid feature in Universal Dependencies, even if absent in modern Polish.
\end{itemize}

\subsection{Post-conversion}
Finally, a sentence-level cleanup function performs two crucial tasks that require the original, non-tokenized text from the metadata:

\begin{enumerate}[leftmargin=2em]
    \item \textbf{Reconstructing Multiword Tokens:} This step correctly formats clitic constructions that were already split into syntactic words in the input data. For example, for the Middle Polish word \textit{kiedym} (`when I'), the input \texttt{.conll} file contains two separate token lines (\textit{kiedy} and \textit{m}). This function reads the original text, sees they are not space-separated, and inserts the required multiword token (MWE) entry (e.g., \texttt{14-15 kiedym ...}) before the syntactic words it spans, as shown in the example in Chapter~\ref{sec:universal-dependencies}.

    \item \textbf{Annotating Spaces:} The same function analyzes the original text to add \texttt{SpaceAfter=No} to the \texttt{MISC} column for any token that is immediately followed by another token or punctuation mark without an intervening space. This is a requirement for the CoNLL-U format since Universal Dependencies v. 2.0.
\end{enumerate}

\section{Phase 2: Dependency Conversion}

The second phase, managed by~the \texttt{dependency/} module, is significantly more complex. Unlike morphosyntax, dependency conversion is not token-local; rules must consider a~token's governor, its dependents, and its siblings, often operating on~the original PDB structure, the partially converted UD structure, or both.

Many of~the structural transformations were adapted from~the principles established for~the conversion of~the contemporary Polish Dependency Bank (PDB$\rightarrow$PDB-UD) \parencite{wroblewska-2018-extended, wroblewska-2020-towards}, but were re-implemented to~fit the custom pipeline and~handle Middle Polish phenomena. The conversion follows a~strict pipeline, defined in~\texttt{dependency/conversion.py}.

\subsection{Structural Restructuring}
The first and most critical step is to~change the topology of~the dependency tree. The \texttt{dependency/structures/} directory contains modules for~specific syntactic constructions. The two most fundamental transformations, which were illustrated in~\autoref{fig:pdb-example} and \autoref{fig:ud-example}, are:

\begin{itemize}[leftmargin=2em]
    \item \textbf{Prepositional Phrases:} In~PDB, a~preposition (\texttt{prep}) governs its nominal complement (\texttt{comp}). The \texttt{dependency/structures/prepositional.py} module inverts this: the nominal complement becomes the head, it inherits the dependency relation from~the preposition (e.g., \texttt{adjunct} $\rightarrow$ \texttt{obl}), and the preposition is re-attached to~the noun with the \texttt{case} relation.
    
    \item \textbf{Coordination:} In~PDB, the coordinating conjunction (\texttt{conj}) is the head of~the coordinated elements (\texttt{conjunct}). The \texttt{dependency/structures/coordination.py} module restructures this by~promoting the \emph{first} conjunct to~be the head. Subsequent conjuncts are attached to~the first with the \texttt{conj} relation, and the conjunction itself is attached to~its \emph{following} conjunct with the \texttt{cc} relation.
\end{itemize}

Similar restructuring logic is applied to~copula constructions (\texttt{copula.py}), numeral phrases (\texttt{numeral.py}), and subordinate clauses (\texttt{subordination.py}).

\subsection{Label Mapping}
After the tree structure is finalized, the \texttt{dependency/labels.py} module traverses the tree and assigns a~final \texttt{udep\_label} to~each token. This mapping is highly context-sensitive. For~example, the generic PDB \texttt{adjunct} relation is mapped to~a~variety of~UD relations based on~the UPOS of~the head and the dependent:
\begin{itemize}[leftmargin=2em]
    \item \texttt{adjunct} on~a~\texttt{NOUN} dependent $\rightarrow$ \texttt{nmod}
    \item \texttt{adjunct} on~an \texttt{ADJ} dependent $\rightarrow$ \texttt{amod}
    \item \texttt{adjunct} on~an \texttt{ADV} dependent $\rightarrow$ \texttt{advmod}
    \item \texttt{adjunct} (prepositional phrase) on~a~\texttt{VERB} $\rightarrow$ \texttt{obl}
    \item \texttt{adjunct} (clausal) on~a~\texttt{VERB} $\rightarrow$ \texttt{advcl}
\end{itemize}

\subsection{Correction and Post-processing}
Finally, a~series of~cleanup scripts are run. \texttt{dependency/edges.py} ensures UD validation compliance by~removing disallowed dependents (e.g., a~\texttt{case} token cannot have its own dependents).

The \texttt{dependency/postconversion.py} module handles final tasks, such as disambiguating pronouns (\texttt{PronType=Int,Rel} $\rightarrow$ \texttt{PronType=Int} or \texttt{PronType=Rel} based on~tree context) and, most importantly, generating the enhanced dependency graph (\texttt{DEPS} column) by~propagating shared dependents in~coordination, fulfilling goal \textbf{(R3)}.

\section{Processing Workflow}

From a~user's perspective, the pipeline is executed via~a~single command. The converter takes the MPDT \texttt{.conll} file and the corresponding metadata \texttt{.json} file as~input.

\begin{verbatim}
python converter.py input_file.conll output_file.conllu meta_file.json
\end{verbatim}

The script processes each sentence and saves the result in~the specified \texttt{output\_file.conllu} in~the valid CoNLL-U format, ready for~validation and downstream use.

\end{document}